{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73c32414-0003-4570-b083-f2b203d73ff5",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86809a19-84c3-4c8d-8177-ef9dbf5fb9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fbdaf5-17a0-4e0d-a1bc-5fa44e6f2542",
   "metadata": {},
   "source": [
    "- PyTorch is a library for processing tensors. A tensor is a number, vector, matrix or any n-dimensional array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a637b469-6705-42f1-baf9-72ad3c46db0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number\n",
    "t1 = torch.tensor(4.)\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e1249a-edac-4153-8b88-6d0b3a0f3335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1a792c-ec43-4592-9017-c44f2debb7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector(Array)\n",
    "t2=torch.tensor([1.,2.,3.,4.])\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fff289-2d86-4afe-9a73-5183b15ca171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e697154-1c1e-4ff7-8e14-492e8032aba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix\n",
    "t3=torch.tensor([[5.,6.],\n",
    "                [7,8],\n",
    "                [9,10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b29616-35b9-4382-acde-2cd3ca79704e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.,  6.],\n",
       "        [ 7.,  8.],\n",
       "        [ 9., 10.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7212ba-bd8e-43f2-a778-1b7791d0de07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b725518-5ae4-4c56-9dbd-3cb72bd755b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[11, 12, 13],\n",
       "         [13, 14, 15]],\n",
       "\n",
       "        [[15, 16, 17],\n",
       "         [17, 18, 19]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3-Dimensional array\n",
    "t4=torch.tensor([\n",
    "    [[11,12,13],\n",
    "    [13,14,15]],\n",
    "    [[15,16,17],\n",
    "    [17,18,19]]\n",
    "])\n",
    "t4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d79668-e5d1-41d3-96fc-b577df6f1f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da7324d-b858-4995-a9bc-cde5de8ea249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t4.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f932becf-74bd-4152-b57b-85e50ddd7c1d",
   "metadata": {},
   "source": [
    "#### Tensor Operations and Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4c286c-6091-462f-bb8a-93a321d890e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tensors\n",
    "x=torch.tensor(3.)\n",
    "w=torch.tensor(4.,requires_grad=True) # We are alerting him that it can be used for differentiation\n",
    "b=torch.tensor(5.,requires_grad=True) # We are alerting him that it can be used for differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799743d8-e753-43ff-bc77-49f7ebbd2897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3.), tensor(4., requires_grad=True), tensor(5., requires_grad=True))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0933eb-62b1-4ccc-9157-6e2ebd7f166e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arithmetic Operations\n",
    "y=w*x+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c17215b-8986-484f-9865-c785f0fb8fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17., grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c19737-82d1-4cad-9acb-c2e5237904af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Derivatives\n",
    "y.backward()  #Backward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b5500f-d950-428d-b706-25fd92baa1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dx:  None\n",
      "dy/dw:  tensor(3.)\n",
      "dy/db:  tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# Display gradients\n",
    "print(\"dy/dx: \",x.grad)\n",
    "print(\"dy/dw: \",w.grad)\n",
    "print(\"dy/db: \",b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011bd5ec-b598-468a-857a-5f03ce2aebde",
   "metadata": {},
   "source": [
    "- Tensor Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5513801c-ae0a-4cf1-9121-d603b2d3f12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[42, 42],\n",
       "        [42, 42],\n",
       "        [42, 42]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor with a fixed value for every element\n",
    "t6=torch.full((3,2),42)\n",
    "t6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ed4a2d-e0b9-4fc7-8c80-b3a51cc56bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.,  6.],\n",
       "        [ 7.,  8.],\n",
       "        [ 9., 10.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5708af83-aa01-4a13-bff0-22d8f51f1a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.,  6.],\n",
       "        [ 7.,  8.],\n",
       "        [ 9., 10.],\n",
       "        [42., 42.],\n",
       "        [42., 42.],\n",
       "        [42., 42.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t7=torch.concat((t3,t6))\n",
    "t7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19030f00-26f1-47b7-b092-0e01defb730b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9589, -0.2794],\n",
       "        [ 0.6570,  0.9894],\n",
       "        [ 0.4121, -0.5440],\n",
       "        [-0.9165, -0.9165],\n",
       "        [-0.9165, -0.9165],\n",
       "        [-0.9165, -0.9165]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the sin of each element\n",
    "t8=torch.sin(t7)\n",
    "t8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99d6354-da66-4da9-bd06-0cd9eaf65ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t8.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ded32a-546e-4c7b-b0a5-4bc2d6576c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the shape of a tensor\n",
    "t9=t8.reshape(3,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5774787b-b6b6-4bf9-bae9-e33f7230b004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9589, -0.2794],\n",
       "         [ 0.6570,  0.9894]],\n",
       "\n",
       "        [[ 0.4121, -0.5440],\n",
       "         [-0.9165, -0.9165]],\n",
       "\n",
       "        [[-0.9165, -0.9165],\n",
       "         [-0.9165, -0.9165]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1219902-02d9-4e8b-87ee-4bd8febfee2d",
   "metadata": {},
   "source": [
    "- Interoperability of PyTorch with Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d147ff1b-1b2d-4583-9646-a43fe273c078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8e7df3-4a05-48d9-a442-415e99c3c1e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.array([[1,2],[3,4]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e107613-9ef1-4e5f-b869-e46a0a1fc06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]], dtype=torch.int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert Numpy array to a PyTorch tensor\n",
    "y=torch.from_numpy(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837b33d7-f5ce-4b4a-a301-040ea27c6e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert torch tensor to Numpy array\n",
    "z=y.numpy()\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9813cb-f19e-4105-9dae-ddfc7d19e25e",
   "metadata": {},
   "source": [
    "### Linear Regression from Scratch using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4dd5f0-211d-47b8-8d6b-8329c1f93acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Training Data\n",
    "# Input: (temperature,rainfall,humidity)\n",
    "inputs=np.array([[73,67,43],\n",
    "                [91,88,64],\n",
    "                [87,134,58],\n",
    "                [102,43,37],\n",
    "                [69,96,70]],dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c485fd0c-1bf7-4ed3-b590-db6ca04a6653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 73.,  67.,  43.],\n",
       "       [ 91.,  88.,  64.],\n",
       "       [ 87., 134.,  58.],\n",
       "       [102.,  43.,  37.],\n",
       "       [ 69.,  96.,  70.]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac32ddb7-488e-4fc0-8f5c-3c35d330ff12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7378e86-f8a6-4c96-bbd7-3f38f554430a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targets (apples,oranges)\n",
    "\n",
    "target=np.array([[56,70],\n",
    "                [81,101],\n",
    "                [119,133],\n",
    "                [22,37],\n",
    "                [103,119]],dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2fe8e9-10d3-49c4-b473-3701dd77afcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 56.,  70.],\n",
       "       [ 81., 101.],\n",
       "       [119., 133.],\n",
       "       [ 22.,  37.],\n",
       "       [103., 119.]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1faa04-226a-4c02-b670-61447cb72985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9614c22-719e-4723-a81a-9b389cd2f8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Input and target to tensors\n",
    "inputs=torch.from_numpy(inputs)\n",
    "target=torch.from_numpy(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e065bc-9e48-417a-ae01-b8980a5e9b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights and biases\n",
    "w=torch.randn(2,3,requires_grad=True)\n",
    "b=torch.randn(2,requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e807f202-4118-4479-9e6f-bc26abe43715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0875,  0.0629,  1.2892],\n",
       "         [-0.2703, -0.8038, -0.1781]], requires_grad=True),\n",
       " tensor([1.2697, 0.3299], requires_grad=True))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a242e251-862b-4a4c-a05a-1d6afc9023c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "\n",
    "def model(x):\n",
    "    return x @ w.t() + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6370bb1b-8be7-4357-9061-67355973c22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  67.3036,  -80.9133],\n",
      "        [  97.2717, -106.3982],\n",
      "        [  92.0802, -141.2233],\n",
      "        [  60.5954,  -68.3914],\n",
      "        [ 103.5858, -107.9512]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "preds=model(inputs)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9f1fd5-ff00-4966-904d-7f3db288c158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "# Actual\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6740a8b3-acf6-42b1-8dc2-02a4b3166135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function MSE\n",
    "\n",
    "def MSE(actual,pred):\n",
    "    diff=actual-pred\n",
    "    return torch.sum(diff*diff)/diff.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a262f2e-7a77-4176-92e7-732b4dae9625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(20620.8633, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss=MSE(target,preds)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf8b609-2f96-491e-9fb9-e95a27f23564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Gradients\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9573681-1760-4281-a374-9c620bec7fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0875,  0.0629,  1.2892],\n",
      "        [-0.2703, -0.8038, -0.1781]], requires_grad=True)\n",
      "tensor([[   788.2027,     59.5668,    287.0261],\n",
      "        [-16031.3779, -18285.4609, -11090.7559]])\n"
     ]
    }
   ],
   "source": [
    "print(w)\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281e4af7-b071-4bce-aa62-ac678706b5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2697, 0.3299], requires_grad=True)\n",
      "tensor([   7.9673, -192.9755])\n"
     ]
    }
   ],
   "source": [
    "print(b)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9a3fe6-2cd3-456f-8598-e4f966ec08b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust weight and reset grad\n",
    "with torch.no_grad():\n",
    "    w-=w.grad * 1e-5;\n",
    "    b-=b.grad * 1e-5;\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7904e6d4-99f1-4677-953e-53ae78c02342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0796,  0.0623,  1.2863],\n",
      "        [-0.1100, -0.6209, -0.0672]], requires_grad=True)\n",
      "tensor([1.2697, 0.3318], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab329893-1447-48f4-8b18-37619e46536f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14109.3877, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Calculate again\n",
    "preds=model(inputs)\n",
    "loss=MSE(target,preds)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72865c4-d013-4c15-bddd-bfff9da17969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs(0/100) & Loss 14109.3876953125\n",
      "Epochs(1/100) & Loss 9718.8251953125\n",
      "Epochs(2/100) & Loss 6757.54296875\n",
      "Epochs(3/100) & Loss 4759.4658203125\n",
      "Epochs(4/100) & Loss 3410.510498046875\n",
      "Epochs(5/100) & Loss 2499.019287109375\n",
      "Epochs(6/100) & Loss 1882.3603515625\n",
      "Epochs(7/100) & Loss 1464.4146728515625\n",
      "Epochs(8/100) & Loss 1180.4085693359375\n",
      "Epochs(9/100) & Loss 986.6923828125\n",
      "Epochs(10/100) & Loss 853.8504028320312\n",
      "Epochs(11/100) & Loss 762.0594482421875\n",
      "Epochs(12/100) & Loss 697.9608764648438\n",
      "Epochs(13/100) & Loss 652.5513916015625\n",
      "Epochs(14/100) & Loss 619.7646484375\n",
      "Epochs(15/100) & Loss 595.5110473632812\n",
      "Epochs(16/100) & Loss 577.0350341796875\n",
      "Epochs(17/100) & Loss 562.4791259765625\n",
      "Epochs(18/100) & Loss 550.5914306640625\n",
      "Epochs(19/100) & Loss 540.5276489257812\n",
      "Epochs(20/100) & Loss 531.7188720703125\n",
      "Epochs(21/100) & Loss 523.7811279296875\n",
      "Epochs(22/100) & Loss 516.4554443359375\n",
      "Epochs(23/100) & Loss 509.56695556640625\n",
      "Epochs(24/100) & Loss 502.99755859375\n",
      "Epochs(25/100) & Loss 496.6673889160156\n",
      "Epochs(26/100) & Loss 490.5220642089844\n",
      "Epochs(27/100) & Loss 484.52496337890625\n",
      "Epochs(28/100) & Loss 478.6509704589844\n",
      "Epochs(29/100) & Loss 472.8829040527344\n",
      "Epochs(30/100) & Loss 467.2088317871094\n",
      "Epochs(31/100) & Loss 461.62030029296875\n",
      "Epochs(32/100) & Loss 456.11181640625\n",
      "Epochs(33/100) & Loss 450.6788024902344\n",
      "Epochs(34/100) & Loss 445.3184509277344\n",
      "Epochs(35/100) & Loss 440.028076171875\n",
      "Epochs(36/100) & Loss 434.805908203125\n",
      "Epochs(37/100) & Loss 429.650390625\n",
      "Epochs(38/100) & Loss 424.5604553222656\n",
      "Epochs(39/100) & Loss 419.53466796875\n",
      "Epochs(40/100) & Loss 414.572265625\n",
      "Epochs(41/100) & Loss 409.67205810546875\n",
      "Epochs(42/100) & Loss 404.8334045410156\n",
      "Epochs(43/100) & Loss 400.0552673339844\n",
      "Epochs(44/100) & Loss 395.3370056152344\n",
      "Epochs(45/100) & Loss 390.67767333984375\n",
      "Epochs(46/100) & Loss 386.07684326171875\n",
      "Epochs(47/100) & Loss 381.5333557128906\n",
      "Epochs(48/100) & Loss 377.04669189453125\n",
      "Epochs(49/100) & Loss 372.6160583496094\n",
      "Epochs(50/100) & Loss 368.24072265625\n",
      "Epochs(51/100) & Loss 363.920166015625\n",
      "Epochs(52/100) & Loss 359.653564453125\n",
      "Epochs(53/100) & Loss 355.440185546875\n",
      "Epochs(54/100) & Loss 351.2793884277344\n",
      "Epochs(55/100) & Loss 347.170654296875\n",
      "Epochs(56/100) & Loss 343.1130676269531\n",
      "Epochs(57/100) & Loss 339.1061096191406\n",
      "Epochs(58/100) & Loss 335.1492614746094\n",
      "Epochs(59/100) & Loss 331.24176025390625\n",
      "Epochs(60/100) & Loss 327.38299560546875\n",
      "Epochs(61/100) & Loss 323.57232666015625\n",
      "Epochs(62/100) & Loss 319.8092346191406\n",
      "Epochs(63/100) & Loss 316.0931091308594\n",
      "Epochs(64/100) & Loss 312.4232482910156\n",
      "Epochs(65/100) & Loss 308.7992248535156\n",
      "Epochs(66/100) & Loss 305.22021484375\n",
      "Epochs(67/100) & Loss 301.68597412109375\n",
      "Epochs(68/100) & Loss 298.1957092285156\n",
      "Epochs(69/100) & Loss 294.7489318847656\n",
      "Epochs(70/100) & Loss 291.34515380859375\n",
      "Epochs(71/100) & Loss 287.98370361328125\n",
      "Epochs(72/100) & Loss 284.6641845703125\n",
      "Epochs(73/100) & Loss 281.385986328125\n",
      "Epochs(74/100) & Loss 278.14862060546875\n",
      "Epochs(75/100) & Loss 274.9515686035156\n",
      "Epochs(76/100) & Loss 271.794189453125\n",
      "Epochs(77/100) & Loss 268.67620849609375\n",
      "Epochs(78/100) & Loss 265.5970458984375\n",
      "Epochs(79/100) & Loss 262.55615234375\n",
      "Epochs(80/100) & Loss 259.55303955078125\n",
      "Epochs(81/100) & Loss 256.5873107910156\n",
      "Epochs(82/100) & Loss 253.65853881835938\n",
      "Epochs(83/100) & Loss 250.76614379882812\n",
      "Epochs(84/100) & Loss 247.90963745117188\n",
      "Epochs(85/100) & Loss 245.0886688232422\n",
      "Epochs(86/100) & Loss 242.3027801513672\n",
      "Epochs(87/100) & Loss 239.551513671875\n",
      "Epochs(88/100) & Loss 236.83444213867188\n",
      "Epochs(89/100) & Loss 234.1510009765625\n",
      "Epochs(90/100) & Loss 231.5010223388672\n",
      "Epochs(91/100) & Loss 228.8837890625\n",
      "Epochs(92/100) & Loss 226.29928588867188\n",
      "Epochs(93/100) & Loss 223.74673461914062\n",
      "Epochs(94/100) & Loss 221.225830078125\n",
      "Epochs(95/100) & Loss 218.73623657226562\n",
      "Epochs(96/100) & Loss 216.27743530273438\n",
      "Epochs(97/100) & Loss 213.84927368164062\n",
      "Epochs(98/100) & Loss 211.4511260986328\n",
      "Epochs(99/100) & Loss 209.082763671875\n",
      "Epochs(100/100) & Loss 206.74374389648438\n",
      "Epochs(101/100) & Loss 204.4337615966797\n",
      "Epochs(102/100) & Loss 202.15225219726562\n",
      "Epochs(103/100) & Loss 199.8991241455078\n",
      "Epochs(104/100) & Loss 197.673828125\n",
      "Epochs(105/100) & Loss 195.4761962890625\n",
      "Epochs(106/100) & Loss 193.30569458007812\n",
      "Epochs(107/100) & Loss 191.1620635986328\n",
      "Epochs(108/100) & Loss 189.04495239257812\n",
      "Epochs(109/100) & Loss 186.9540557861328\n",
      "Epochs(110/100) & Loss 184.88900756835938\n",
      "Epochs(111/100) & Loss 182.84950256347656\n",
      "Epochs(112/100) & Loss 180.83518981933594\n",
      "Epochs(113/100) & Loss 178.8458251953125\n",
      "Epochs(114/100) & Loss 176.8810272216797\n",
      "Epochs(115/100) & Loss 174.94052124023438\n",
      "Epochs(116/100) & Loss 173.02391052246094\n",
      "Epochs(117/100) & Loss 171.1310272216797\n",
      "Epochs(118/100) & Loss 169.2615509033203\n",
      "Epochs(119/100) & Loss 167.41505432128906\n",
      "Epochs(120/100) & Loss 165.5914764404297\n",
      "Epochs(121/100) & Loss 163.7902069091797\n",
      "Epochs(122/100) & Loss 162.01126098632812\n",
      "Epochs(123/100) & Loss 160.25428771972656\n",
      "Epochs(124/100) & Loss 158.5189666748047\n",
      "Epochs(125/100) & Loss 156.8050079345703\n",
      "Epochs(126/100) & Loss 155.11212158203125\n",
      "Epochs(127/100) & Loss 153.440185546875\n",
      "Epochs(128/100) & Loss 151.78878784179688\n",
      "Epochs(129/100) & Loss 150.15768432617188\n",
      "Epochs(130/100) & Loss 148.54669189453125\n",
      "Epochs(131/100) & Loss 146.95556640625\n",
      "Epochs(132/100) & Loss 145.3839569091797\n",
      "Epochs(133/100) & Loss 143.8317108154297\n",
      "Epochs(134/100) & Loss 142.2985382080078\n",
      "Epochs(135/100) & Loss 140.7842559814453\n",
      "Epochs(136/100) & Loss 139.28848266601562\n",
      "Epochs(137/100) & Loss 137.8111572265625\n",
      "Epochs(138/100) & Loss 136.35195922851562\n",
      "Epochs(139/100) & Loss 134.91067504882812\n",
      "Epochs(140/100) & Loss 133.48703002929688\n",
      "Epochs(141/100) & Loss 132.08084106445312\n",
      "Epochs(142/100) & Loss 130.6919403076172\n",
      "Epochs(143/100) & Loss 129.32008361816406\n",
      "Epochs(144/100) & Loss 127.96507263183594\n",
      "Epochs(145/100) & Loss 126.6266860961914\n",
      "Epochs(146/100) & Loss 125.30461120605469\n",
      "Epochs(147/100) & Loss 123.9987564086914\n",
      "Epochs(148/100) & Loss 122.70893859863281\n",
      "Epochs(149/100) & Loss 121.43482971191406\n",
      "Epochs(150/100) & Loss 120.17635345458984\n",
      "Epochs(151/100) & Loss 118.9332275390625\n",
      "Epochs(152/100) & Loss 117.70533752441406\n",
      "Epochs(153/100) & Loss 116.49247741699219\n",
      "Epochs(154/100) & Loss 115.29443359375\n",
      "Epochs(155/100) & Loss 114.11094665527344\n",
      "Epochs(156/100) & Loss 112.94194030761719\n",
      "Epochs(157/100) & Loss 111.78724670410156\n",
      "Epochs(158/100) & Loss 110.6465835571289\n",
      "Epochs(159/100) & Loss 109.51983642578125\n",
      "Epochs(160/100) & Loss 108.40687561035156\n",
      "Epochs(161/100) & Loss 107.30743408203125\n",
      "Epochs(162/100) & Loss 106.22142028808594\n",
      "Epochs(163/100) & Loss 105.14860534667969\n",
      "Epochs(164/100) & Loss 104.08882904052734\n",
      "Epochs(165/100) & Loss 103.04197692871094\n",
      "Epochs(166/100) & Loss 102.00785827636719\n",
      "Epochs(167/100) & Loss 100.98628997802734\n",
      "Epochs(168/100) & Loss 99.9771499633789\n",
      "Epochs(169/100) & Loss 98.98030853271484\n",
      "Epochs(170/100) & Loss 97.99552154541016\n",
      "Epochs(171/100) & Loss 97.02268981933594\n",
      "Epochs(172/100) & Loss 96.06168365478516\n",
      "Epochs(173/100) & Loss 95.11226654052734\n",
      "Epochs(174/100) & Loss 94.17445373535156\n",
      "Epochs(175/100) & Loss 93.24797058105469\n",
      "Epochs(176/100) & Loss 92.33272552490234\n",
      "Epochs(177/100) & Loss 91.42854309082031\n",
      "Epochs(178/100) & Loss 90.53532409667969\n",
      "Epochs(179/100) & Loss 89.65289306640625\n",
      "Epochs(180/100) & Loss 88.78111267089844\n",
      "Epochs(181/100) & Loss 87.91984558105469\n",
      "Epochs(182/100) & Loss 87.06900024414062\n",
      "Epochs(183/100) & Loss 86.22845458984375\n",
      "Epochs(184/100) & Loss 85.3980484008789\n",
      "Epochs(185/100) & Loss 84.57762145996094\n",
      "Epochs(186/100) & Loss 83.76716613769531\n",
      "Epochs(187/100) & Loss 82.9664535522461\n",
      "Epochs(188/100) & Loss 82.17530822753906\n",
      "Epochs(189/100) & Loss 81.3936996459961\n",
      "Epochs(190/100) & Loss 80.62158203125\n",
      "Epochs(191/100) & Loss 79.85868072509766\n",
      "Epochs(192/100) & Loss 79.10501861572266\n",
      "Epochs(193/100) & Loss 78.36034393310547\n",
      "Epochs(194/100) & Loss 77.62459564208984\n",
      "Epochs(195/100) & Loss 76.89775085449219\n",
      "Epochs(196/100) & Loss 76.17958068847656\n",
      "Epochs(197/100) & Loss 75.47000885009766\n",
      "Epochs(198/100) & Loss 74.7689437866211\n",
      "Epochs(199/100) & Loss 74.07630920410156\n",
      "Epochs(200/100) & Loss 73.39192199707031\n",
      "Epochs(201/100) & Loss 72.71573638916016\n",
      "Epochs(202/100) & Loss 72.04768371582031\n",
      "Epochs(203/100) & Loss 71.38752746582031\n",
      "Epochs(204/100) & Loss 70.73532104492188\n",
      "Epochs(205/100) & Loss 70.09086608886719\n",
      "Epochs(206/100) & Loss 69.45408630371094\n",
      "Epochs(207/100) & Loss 68.82494354248047\n",
      "Epochs(208/100) & Loss 68.20323181152344\n",
      "Epochs(209/100) & Loss 67.58895111083984\n",
      "Epochs(210/100) & Loss 66.98201751708984\n",
      "Epochs(211/100) & Loss 66.38218688964844\n",
      "Epochs(212/100) & Loss 65.78964233398438\n",
      "Epochs(213/100) & Loss 65.20401763916016\n",
      "Epochs(214/100) & Loss 64.62538146972656\n",
      "Epochs(215/100) & Loss 64.05364990234375\n",
      "Epochs(216/100) & Loss 63.48862838745117\n",
      "Epochs(217/100) & Loss 62.9303092956543\n",
      "Epochs(218/100) & Loss 62.37865447998047\n",
      "Epochs(219/100) & Loss 61.83343505859375\n",
      "Epochs(220/100) & Loss 61.294776916503906\n",
      "Epochs(221/100) & Loss 60.762351989746094\n",
      "Epochs(222/100) & Loss 60.2363166809082\n",
      "Epochs(223/100) & Loss 59.7164421081543\n",
      "Epochs(224/100) & Loss 59.202720642089844\n",
      "Epochs(225/100) & Loss 58.694984436035156\n",
      "Epochs(226/100) & Loss 58.19330596923828\n",
      "Epochs(227/100) & Loss 57.69745635986328\n",
      "Epochs(228/100) & Loss 57.20751190185547\n",
      "Epochs(229/100) & Loss 56.723243713378906\n",
      "Epochs(230/100) & Loss 56.244712829589844\n",
      "Epochs(231/100) & Loss 55.771766662597656\n",
      "Epochs(232/100) & Loss 55.30438232421875\n",
      "Epochs(233/100) & Loss 54.84248733520508\n",
      "Epochs(234/100) & Loss 54.38594436645508\n",
      "Epochs(235/100) & Loss 53.93477249145508\n",
      "Epochs(236/100) & Loss 53.48883056640625\n",
      "Epochs(237/100) & Loss 53.04814529418945\n",
      "Epochs(238/100) & Loss 52.612586975097656\n",
      "Epochs(239/100) & Loss 52.182106018066406\n",
      "Epochs(240/100) & Loss 51.75664138793945\n",
      "Epochs(241/100) & Loss 51.33610916137695\n",
      "Epochs(242/100) & Loss 50.92049026489258\n",
      "Epochs(243/100) & Loss 50.509639739990234\n",
      "Epochs(244/100) & Loss 50.10361862182617\n",
      "Epochs(245/100) & Loss 49.70229721069336\n",
      "Epochs(246/100) & Loss 49.30559158325195\n",
      "Epochs(247/100) & Loss 48.913490295410156\n",
      "Epochs(248/100) & Loss 48.52593994140625\n",
      "Epochs(249/100) & Loss 48.1428337097168\n",
      "Epochs(250/100) & Loss 47.764190673828125\n",
      "Epochs(251/100) & Loss 47.38993453979492\n",
      "Epochs(252/100) & Loss 47.01992416381836\n",
      "Epochs(253/100) & Loss 46.65418243408203\n",
      "Epochs(254/100) & Loss 46.29268264770508\n",
      "Epochs(255/100) & Loss 45.93531036376953\n",
      "Epochs(256/100) & Loss 45.58203887939453\n",
      "Epochs(257/100) & Loss 45.23284912109375\n",
      "Epochs(258/100) & Loss 44.887596130371094\n",
      "Epochs(259/100) & Loss 44.546363830566406\n",
      "Epochs(260/100) & Loss 44.208984375\n",
      "Epochs(261/100) & Loss 43.87546920776367\n",
      "Epochs(262/100) & Loss 43.545753479003906\n",
      "Epochs(263/100) & Loss 43.21980667114258\n",
      "Epochs(264/100) & Loss 42.897586822509766\n",
      "Epochs(265/100) & Loss 42.579017639160156\n",
      "Epochs(266/100) & Loss 42.26407241821289\n",
      "Epochs(267/100) & Loss 41.952667236328125\n",
      "Epochs(268/100) & Loss 41.64484405517578\n",
      "Epochs(269/100) & Loss 41.34044647216797\n",
      "Epochs(270/100) & Loss 41.03955841064453\n",
      "Epochs(271/100) & Loss 40.74203872680664\n",
      "Epochs(272/100) & Loss 40.44786071777344\n",
      "Epochs(273/100) & Loss 40.157012939453125\n",
      "Epochs(274/100) & Loss 39.86945343017578\n",
      "Epochs(275/100) & Loss 39.58511734008789\n",
      "Epochs(276/100) & Loss 39.3039665222168\n",
      "Epochs(277/100) & Loss 39.025978088378906\n",
      "Epochs(278/100) & Loss 38.751129150390625\n",
      "Epochs(279/100) & Loss 38.47934341430664\n",
      "Epochs(280/100) & Loss 38.210567474365234\n",
      "Epochs(281/100) & Loss 37.94479751586914\n",
      "Epochs(282/100) & Loss 37.682003021240234\n",
      "Epochs(283/100) & Loss 37.42216110229492\n",
      "Epochs(284/100) & Loss 37.16519546508789\n",
      "Epochs(285/100) & Loss 36.911048889160156\n",
      "Epochs(286/100) & Loss 36.65977478027344\n",
      "Epochs(287/100) & Loss 36.4112434387207\n",
      "Epochs(288/100) & Loss 36.16547775268555\n",
      "Epochs(289/100) & Loss 35.922454833984375\n",
      "Epochs(290/100) & Loss 35.68210983276367\n",
      "Epochs(291/100) & Loss 35.444393157958984\n",
      "Epochs(292/100) & Loss 35.209320068359375\n",
      "Epochs(293/100) & Loss 34.976768493652344\n",
      "Epochs(294/100) & Loss 34.74686050415039\n",
      "Epochs(295/100) & Loss 34.51941680908203\n",
      "Epochs(296/100) & Loss 34.29447555541992\n",
      "Epochs(297/100) & Loss 34.071983337402344\n",
      "Epochs(298/100) & Loss 33.851932525634766\n",
      "Epochs(299/100) & Loss 33.63426208496094\n",
      "Epochs(300/100) & Loss 33.418968200683594\n",
      "Epochs(301/100) & Loss 33.20606231689453\n",
      "Epochs(302/100) & Loss 32.995426177978516\n",
      "Epochs(303/100) & Loss 32.78707504272461\n",
      "Epochs(304/100) & Loss 32.580970764160156\n",
      "Epochs(305/100) & Loss 32.37712478637695\n",
      "Epochs(306/100) & Loss 32.17546844482422\n",
      "Epochs(307/100) & Loss 31.975967407226562\n",
      "Epochs(308/100) & Loss 31.778606414794922\n",
      "Epochs(309/100) & Loss 31.583385467529297\n",
      "Epochs(310/100) & Loss 31.39023780822754\n",
      "Epochs(311/100) & Loss 31.199188232421875\n",
      "Epochs(312/100) & Loss 31.0101318359375\n",
      "Epochs(313/100) & Loss 30.82314682006836\n",
      "Epochs(314/100) & Loss 30.638137817382812\n",
      "Epochs(315/100) & Loss 30.455089569091797\n",
      "Epochs(316/100) & Loss 30.274005889892578\n",
      "Epochs(317/100) & Loss 30.09479331970215\n",
      "Epochs(318/100) & Loss 29.917505264282227\n",
      "Epochs(319/100) & Loss 29.742090225219727\n",
      "Epochs(320/100) & Loss 29.568527221679688\n",
      "Epochs(321/100) & Loss 29.396808624267578\n",
      "Epochs(322/100) & Loss 29.226856231689453\n",
      "Epochs(323/100) & Loss 29.058727264404297\n",
      "Epochs(324/100) & Loss 28.892345428466797\n",
      "Epochs(325/100) & Loss 28.727703094482422\n",
      "Epochs(326/100) & Loss 28.564788818359375\n",
      "Epochs(327/100) & Loss 28.403545379638672\n",
      "Epochs(328/100) & Loss 28.244007110595703\n",
      "Epochs(329/100) & Loss 28.08609390258789\n",
      "Epochs(330/100) & Loss 27.92983055114746\n",
      "Epochs(331/100) & Loss 27.775192260742188\n",
      "Epochs(332/100) & Loss 27.62213134765625\n",
      "Epochs(333/100) & Loss 27.470661163330078\n",
      "Epochs(334/100) & Loss 27.32074546813965\n",
      "Epochs(335/100) & Loss 27.172372817993164\n",
      "Epochs(336/100) & Loss 27.0255069732666\n",
      "Epochs(337/100) & Loss 26.880168914794922\n",
      "Epochs(338/100) & Loss 26.736303329467773\n",
      "Epochs(339/100) & Loss 26.59389305114746\n",
      "Epochs(340/100) & Loss 26.452892303466797\n",
      "Epochs(341/100) & Loss 26.313373565673828\n",
      "Epochs(342/100) & Loss 26.17527198791504\n",
      "Epochs(343/100) & Loss 26.038522720336914\n",
      "Epochs(344/100) & Loss 25.903179168701172\n",
      "Epochs(345/100) & Loss 25.769216537475586\n",
      "Epochs(346/100) & Loss 25.63656997680664\n",
      "Epochs(347/100) & Loss 25.5052490234375\n",
      "Epochs(348/100) & Loss 25.375240325927734\n",
      "Epochs(349/100) & Loss 25.24652099609375\n",
      "Epochs(350/100) & Loss 25.119104385375977\n",
      "Epochs(351/100) & Loss 24.99294090270996\n",
      "Epochs(352/100) & Loss 24.86802101135254\n",
      "Epochs(353/100) & Loss 24.744354248046875\n",
      "Epochs(354/100) & Loss 24.62186622619629\n",
      "Epochs(355/100) & Loss 24.500635147094727\n",
      "Epochs(356/100) & Loss 24.380558013916016\n",
      "Epochs(357/100) & Loss 24.26167106628418\n",
      "Epochs(358/100) & Loss 24.14394187927246\n",
      "Epochs(359/100) & Loss 24.02738380432129\n",
      "Epochs(360/100) & Loss 23.911909103393555\n",
      "Epochs(361/100) & Loss 23.797574996948242\n",
      "Epochs(362/100) & Loss 23.68435287475586\n",
      "Epochs(363/100) & Loss 23.572256088256836\n",
      "Epochs(364/100) & Loss 23.461193084716797\n",
      "Epochs(365/100) & Loss 23.351207733154297\n",
      "Epochs(366/100) & Loss 23.242277145385742\n",
      "Epochs(367/100) & Loss 23.134403228759766\n",
      "Epochs(368/100) & Loss 23.02754020690918\n",
      "Epochs(369/100) & Loss 22.921695709228516\n",
      "Epochs(370/100) & Loss 22.816884994506836\n",
      "Epochs(371/100) & Loss 22.713043212890625\n",
      "Epochs(372/100) & Loss 22.610172271728516\n",
      "Epochs(373/100) & Loss 22.508251190185547\n",
      "Epochs(374/100) & Loss 22.40733528137207\n",
      "Epochs(375/100) & Loss 22.307336807250977\n",
      "Epochs(376/100) & Loss 22.208263397216797\n",
      "Epochs(377/100) & Loss 22.110126495361328\n",
      "Epochs(378/100) & Loss 22.01289939880371\n",
      "Epochs(379/100) & Loss 21.91657829284668\n",
      "Epochs(380/100) & Loss 21.821155548095703\n",
      "Epochs(381/100) & Loss 21.72661781311035\n",
      "Epochs(382/100) & Loss 21.632909774780273\n",
      "Epochs(383/100) & Loss 21.540119171142578\n",
      "Epochs(384/100) & Loss 21.448123931884766\n",
      "Epochs(385/100) & Loss 21.356971740722656\n",
      "Epochs(386/100) & Loss 21.26667594909668\n",
      "Epochs(387/100) & Loss 21.177183151245117\n",
      "Epochs(388/100) & Loss 21.0885009765625\n",
      "Epochs(389/100) & Loss 21.000614166259766\n",
      "Epochs(390/100) & Loss 20.913530349731445\n",
      "Epochs(391/100) & Loss 20.827190399169922\n",
      "Epochs(392/100) & Loss 20.741657257080078\n",
      "Epochs(393/100) & Loss 20.656862258911133\n",
      "Epochs(394/100) & Loss 20.572826385498047\n",
      "Epochs(395/100) & Loss 20.48954200744629\n",
      "Epochs(396/100) & Loss 20.407001495361328\n",
      "Epochs(397/100) & Loss 20.325185775756836\n",
      "Epochs(398/100) & Loss 20.244060516357422\n",
      "Epochs(399/100) & Loss 20.163698196411133\n"
     ]
    }
   ],
   "source": [
    "# Training for multiple epochs\n",
    "for i in range(400):\n",
    "    preds=model(inputs)\n",
    "    loss=MSE(target,preds)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        w-=w.grad * 1e-5; # Learning rate\n",
    "        b-=b.grad * 1e-5;\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()\n",
    "    print(f\"Epochs({i}/{100}) & Loss {loss}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92aab22-20d1-4de7-8eec-bce4d9f1776d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(20.0840, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "preds=model(inputs)\n",
    "loss=MSE(target,preds)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9c4514-0a78-4b21-8c71-35ccffcf7a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.481516920836422"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "sqrt(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb34b1ff-1c11-4609-81ad-a36958650c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 57.4887,  71.3125],\n",
       "        [ 85.8857,  99.2043],\n",
       "        [109.8102, 134.6802],\n",
       "        [ 22.0818,  42.3053],\n",
       "        [107.9858, 113.5668]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b65fefa-9a5f-4d05-8c1f-aca2064d7946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3589cf79-8577-4b7f-8948-112cb2af410a",
   "metadata": {},
   "source": [
    "- Therfore we can see that they are almost close each other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4879a9ec-e8b8-40e1-9e54-b65c11aab1c7",
   "metadata": {},
   "source": [
    "### Neural Network using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961c6c38-54d9-48dc-ba6a-711714f435a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul 10 17:46:40 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 546.26                 Driver Version: 546.26       CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1650      WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   43C    P8               4W /  50W |      0MiB /  4096MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# To check GPU\n",
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
