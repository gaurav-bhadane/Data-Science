{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "73c32414-0003-4570-b083-f2b203d73ff5",
      "metadata": {
        "id": "73c32414-0003-4570-b083-f2b203d73ff5"
      },
      "source": [
        "# PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "86809a19-84c3-4c8d-8177-ef9dbf5fb9f3",
      "metadata": {
        "id": "86809a19-84c3-4c8d-8177-ef9dbf5fb9f3"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54fbdaf5-17a0-4e0d-a1bc-5fa44e6f2542",
      "metadata": {
        "id": "54fbdaf5-17a0-4e0d-a1bc-5fa44e6f2542"
      },
      "source": [
        "- PyTorch is a library for processing tensors. A tensor is a number, vector, matrix or any n-dimensional array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "a637b469-6705-42f1-baf9-72ad3c46db0e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a637b469-6705-42f1-baf9-72ad3c46db0e",
        "outputId": "066c974f-7405-43df-dec6-0ddbbcf6322c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "# Number\n",
        "t1 = torch.tensor(4.)\n",
        "t1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "59e1249a-edac-4153-8b88-6d0b3a0f3335",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59e1249a-edac-4153-8b88-6d0b3a0f3335",
        "outputId": "7f531dc6-eb25-4425-dfb6-108415f045d6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "t1.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "aa1a792c-ec43-4592-9017-c44f2debb7e6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa1a792c-ec43-4592-9017-c44f2debb7e6",
        "outputId": "fe4148dd-9612-4d11-dc0d-5a5cda04746e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3., 4.])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "# Vector(Array)\n",
        "t2=torch.tensor([1.,2.,3.,4.])\n",
        "t2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "72fff289-2d86-4afe-9a73-5183b15ca171",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72fff289-2d86-4afe-9a73-5183b15ca171",
        "outputId": "05fcdc8e-c6fc-4b75-f480-4e634f3b9843"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "t2.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "6e697154-1c1e-4ff7-8e14-492e8032aba7",
      "metadata": {
        "id": "6e697154-1c1e-4ff7-8e14-492e8032aba7"
      },
      "outputs": [],
      "source": [
        "# Matrix\n",
        "t3=torch.tensor([[5.,6.],\n",
        "                [7,8],\n",
        "                [9,10]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "39b29616-35b9-4382-acde-2cd3ca79704e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39b29616-35b9-4382-acde-2cd3ca79704e",
        "outputId": "5a11fd5b-a63c-4011-f3b4-e5326c61be1a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5.,  6.],\n",
              "        [ 7.,  8.],\n",
              "        [ 9., 10.]])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "t3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "5d7212ba-bd8e-43f2-a778-1b7791d0de07",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d7212ba-bd8e-43f2-a778-1b7791d0de07",
        "outputId": "402b067b-281c-42b4-b049-302f579bbb20"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "t3.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "9b725518-5ae4-4c56-9dbd-3cb72bd755b4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b725518-5ae4-4c56-9dbd-3cb72bd755b4",
        "outputId": "bd30d8ee-edc2-4676-f068-c5ea8ea075fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[11, 12, 13],\n",
              "         [13, 14, 15]],\n",
              "\n",
              "        [[15, 16, 17],\n",
              "         [17, 18, 19]]])"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "# 3-Dimensional array\n",
        "t4=torch.tensor([\n",
        "    [[11,12,13],\n",
        "    [13,14,15]],\n",
        "    [[15,16,17],\n",
        "    [17,18,19]]\n",
        "])\n",
        "t4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "54d79668-e5d1-41d3-96fc-b577df6f1f10",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54d79668-e5d1-41d3-96fc-b577df6f1f10",
        "outputId": "bd8f6527-84ec-44b3-c1d3-7436619e9f36"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "t4.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "3da7324d-b858-4995-a9bc-cde5de8ea249",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3da7324d-b858-4995-a9bc-cde5de8ea249",
        "outputId": "abdb269a-98de-4291-8f9d-67ae01e8600a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "t4.size()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f932becf-74bd-4152-b57b-85e50ddd7c1d",
      "metadata": {
        "id": "f932becf-74bd-4152-b57b-85e50ddd7c1d"
      },
      "source": [
        "#### Tensor Operations and Gradients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "5d4c286c-6091-462f-bb8a-93a321d890e0",
      "metadata": {
        "id": "5d4c286c-6091-462f-bb8a-93a321d890e0"
      },
      "outputs": [],
      "source": [
        "# Create Tensors\n",
        "x=torch.tensor(3.)\n",
        "w=torch.tensor(4.,requires_grad=True) # We are alerting him that it can be used for differentiation\n",
        "b=torch.tensor(5.,requires_grad=True) # We are alerting him that it can be used for differentiation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "799743d8-e753-43ff-bc77-49f7ebbd2897",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "799743d8-e753-43ff-bc77-49f7ebbd2897",
        "outputId": "5acc1c7f-5db9-417d-f91d-7c54e66cd040"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(3.), tensor(4., requires_grad=True), tensor(5., requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "x,w,b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "fe0933eb-62b1-4ccc-9157-6e2ebd7f166e",
      "metadata": {
        "id": "fe0933eb-62b1-4ccc-9157-6e2ebd7f166e"
      },
      "outputs": [],
      "source": [
        "# Arithmetic Operations\n",
        "y=w*x+b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "2c17215b-8986-484f-9865-c785f0fb8fd6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c17215b-8986-484f-9865-c785f0fb8fd6",
        "outputId": "c0991333-1d69-4e1e-cdef-8e51281d3680"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(17., grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "70c19737-82d1-4cad-9acb-c2e5237904af",
      "metadata": {
        "id": "70c19737-82d1-4cad-9acb-c2e5237904af"
      },
      "outputs": [],
      "source": [
        "# Compute Derivatives\n",
        "y.backward()  #Backward Propagation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "c8b5500f-d950-428d-b706-25fd92baa1f1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8b5500f-d950-428d-b706-25fd92baa1f1",
        "outputId": "bb8f2fa1-2387-4d32-dd5c-774e84dab954"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dy/dx:  None\n",
            "dy/dw:  tensor(3.)\n",
            "dy/db:  tensor(1.)\n"
          ]
        }
      ],
      "source": [
        "# Display gradients\n",
        "print(\"dy/dx: \",x.grad)\n",
        "print(\"dy/dw: \",w.grad)\n",
        "print(\"dy/db: \",b.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "011bd5ec-b598-468a-857a-5f03ce2aebde",
      "metadata": {
        "id": "011bd5ec-b598-468a-857a-5f03ce2aebde"
      },
      "source": [
        "- Tensor Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "5513801c-ae0a-4cf1-9121-d603b2d3f12f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5513801c-ae0a-4cf1-9121-d603b2d3f12f",
        "outputId": "c8f6388f-4abc-4c1a-fac8-7df50a535073"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[42, 42],\n",
              "        [42, 42],\n",
              "        [42, 42]])"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ],
      "source": [
        "# Create a tensor with a fixed value for every element\n",
        "t6=torch.full((3,2),42)\n",
        "t6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "e1ed4a2d-e0b9-4fc7-8c80-b3a51cc56bb0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1ed4a2d-e0b9-4fc7-8c80-b3a51cc56bb0",
        "outputId": "261c38d1-734a-493a-8f05-9ad49a21da17"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5.,  6.],\n",
              "        [ 7.,  8.],\n",
              "        [ 9., 10.]])"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ],
      "source": [
        "t3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "5708af83-aa01-4a13-bff0-22d8f51f1a9b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5708af83-aa01-4a13-bff0-22d8f51f1a9b",
        "outputId": "9a6a4e18-7173-4d5d-a9ab-cd1f38e81cca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5.,  6.],\n",
              "        [ 7.,  8.],\n",
              "        [ 9., 10.],\n",
              "        [42., 42.],\n",
              "        [42., 42.],\n",
              "        [42., 42.]])"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "t7=torch.concat((t3,t6))\n",
        "t7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "19030f00-26f1-47b7-b092-0e01defb730b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19030f00-26f1-47b7-b092-0e01defb730b",
        "outputId": "90e1c23e-9ea4-427a-aa82-67814d0026c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.9589, -0.2794],\n",
              "        [ 0.6570,  0.9894],\n",
              "        [ 0.4121, -0.5440],\n",
              "        [-0.9165, -0.9165],\n",
              "        [-0.9165, -0.9165],\n",
              "        [-0.9165, -0.9165]])"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "# compute the sin of each element\n",
        "t8=torch.sin(t7)\n",
        "t8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "d99d6354-da66-4da9-bd06-0cd9eaf65ecd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d99d6354-da66-4da9-bd06-0cd9eaf65ecd",
        "outputId": "6305b9a0-7613-420f-805d-be93e9f2f95d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "t8.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "02ded32a-546e-4c7b-b0a5-4bc2d6576c98",
      "metadata": {
        "id": "02ded32a-546e-4c7b-b0a5-4bc2d6576c98"
      },
      "outputs": [],
      "source": [
        "# Change the shape of a tensor\n",
        "t9=t8.reshape(3,2,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "5774787b-b6b6-4bf9-bae9-e33f7230b004",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5774787b-b6b6-4bf9-bae9-e33f7230b004",
        "outputId": "16e55fc8-08dc-45da-c1f8-3b653d70ba0c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.9589, -0.2794],\n",
              "         [ 0.6570,  0.9894]],\n",
              "\n",
              "        [[ 0.4121, -0.5440],\n",
              "         [-0.9165, -0.9165]],\n",
              "\n",
              "        [[-0.9165, -0.9165],\n",
              "         [-0.9165, -0.9165]]])"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "t9"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1219902-02d9-4e8b-87ee-4bd8febfee2d",
      "metadata": {
        "id": "a1219902-02d9-4e8b-87ee-4bd8febfee2d"
      },
      "source": [
        "- Interoperability of PyTorch with Numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "d147ff1b-1b2d-4583-9646-a43fe273c078",
      "metadata": {
        "id": "d147ff1b-1b2d-4583-9646-a43fe273c078"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "1c8e7df3-4a05-48d9-a442-415e99c3c1e2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c8e7df3-4a05-48d9-a442-415e99c3c1e2",
        "outputId": "c219b2c0-1960-4999-9e12-7f83e9e6e99e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2],\n",
              "       [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "source": [
        "x=np.array([[1,2],[3,4]])\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "2e107613-9ef1-4e5f-b869-e46a0a1fc06e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e107613-9ef1-4e5f-b869-e46a0a1fc06e",
        "outputId": "e84de786-3fa0-4a28-acfc-32106d889af5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "source": [
        "# Convert Numpy array to a PyTorch tensor\n",
        "y=torch.from_numpy(x)\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "837b33d7-f5ce-4b4a-a301-040ea27c6e7a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "837b33d7-f5ce-4b4a-a301-040ea27c6e7a",
        "outputId": "813596d1-18c1-4e5c-aff9-4bccbf66b4ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2],\n",
              "       [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ],
      "source": [
        "# Convert torch tensor to Numpy array\n",
        "z=y.numpy()\n",
        "z"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf9813cb-f19e-4105-9dae-ddfc7d19e25e",
      "metadata": {
        "id": "bf9813cb-f19e-4105-9dae-ddfc7d19e25e"
      },
      "source": [
        "### Linear Regression from Scratch using PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "ab4dd5f0-211d-47b8-8d6b-8329c1f93acc",
      "metadata": {
        "id": "ab4dd5f0-211d-47b8-8d6b-8329c1f93acc"
      },
      "outputs": [],
      "source": [
        "# Making Training Data\n",
        "# Input: (temperature,rainfall,humidity)\n",
        "inputs=np.array([[73,67,43],\n",
        "                [91,88,64],\n",
        "                [87,134,58],\n",
        "                [102,43,37],\n",
        "                [69,96,70]],dtype='float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "c485fd0c-1bf7-4ed3-b590-db6ca04a6653",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c485fd0c-1bf7-4ed3-b590-db6ca04a6653",
        "outputId": "a1af607f-9100-4065-8d9d-fb13a84595fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 73.,  67.,  43.],\n",
              "       [ 91.,  88.,  64.],\n",
              "       [ 87., 134.,  58.],\n",
              "       [102.,  43.,  37.],\n",
              "       [ 69.,  96.,  70.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ],
      "source": [
        "inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "ac32ddb7-488e-4fc0-8f5c-3c35d330ff12",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac32ddb7-488e-4fc0-8f5c-3c35d330ff12",
        "outputId": "e16cca9f-84d9-434f-9827-beb4783628e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ],
      "source": [
        "inputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "id": "d7378e86-f8a6-4c96-bbd7-3f38f554430a",
      "metadata": {
        "id": "d7378e86-f8a6-4c96-bbd7-3f38f554430a"
      },
      "outputs": [],
      "source": [
        "# Targets (apples,oranges)\n",
        "\n",
        "target=np.array([[56,70],\n",
        "                [81,101],\n",
        "                [119,133],\n",
        "                [22,37],\n",
        "                [103,119]],dtype='float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "id": "fb2fe8e9-10d3-49c4-b473-3701dd77afcb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb2fe8e9-10d3-49c4-b473-3701dd77afcb",
        "outputId": "8a0ff008-94a7-42d6-e630-3380cf3acfef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 56.,  70.],\n",
              "       [ 81., 101.],\n",
              "       [119., 133.],\n",
              "       [ 22.,  37.],\n",
              "       [103., 119.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ],
      "source": [
        "target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "id": "6a1faa04-226a-4c02-b670-61447cb72985",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a1faa04-226a-4c02-b670-61447cb72985",
        "outputId": "0d2a3d17-e7ce-4a67-db78-426bbef399c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ],
      "source": [
        "target.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "id": "f9614c22-719e-4723-a81a-9b389cd2f8a8",
      "metadata": {
        "id": "f9614c22-719e-4723-a81a-9b389cd2f8a8"
      },
      "outputs": [],
      "source": [
        "# Convert Input and target to tensors\n",
        "inputs=torch.from_numpy(inputs)\n",
        "target=torch.from_numpy(target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "id": "80e065bc-9e48-417a-ae01-b8980a5e9b73",
      "metadata": {
        "id": "80e065bc-9e48-417a-ae01-b8980a5e9b73"
      },
      "outputs": [],
      "source": [
        "# weights and biases\n",
        "w=torch.randn(2,3,requires_grad=True)\n",
        "b=torch.randn(2,requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "id": "e807f202-4118-4479-9e6f-bc26abe43715",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e807f202-4118-4479-9e6f-bc26abe43715",
        "outputId": "faaafbb7-66c6-4c1c-dc45-126484aa29e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-0.8495, -1.4858, -0.3431],\n",
              "         [-1.2954,  1.9983, -0.4817]], requires_grad=True),\n",
              " tensor([-0.2907,  1.0617], requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ],
      "source": [
        "w,b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "id": "a242e251-862b-4a4c-a05a-1d6afc9023c0",
      "metadata": {
        "id": "a242e251-862b-4a4c-a05a-1d6afc9023c0"
      },
      "outputs": [],
      "source": [
        "# Define the model\n",
        "\n",
        "def model(x):\n",
        "    return x @ w.t() + b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "id": "6370bb1b-8be7-4357-9061-67355973c22f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6370bb1b-8be7-4357-9061-67355973c22f",
        "outputId": "10055491-7228-4513-8d0a-abdc327c2ba0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-176.6033,   19.6693],\n",
            "        [-230.3003,   28.1998],\n",
            "        [-293.1910,  128.1932],\n",
            "        [-163.5202,  -62.9652],\n",
            "        [-225.5569,   69.7940]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Prediction\n",
        "preds=model(inputs)\n",
        "print(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "id": "0f9f1fd5-ff00-4966-904d-7f3db288c158",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f9f1fd5-ff00-4966-904d-7f3db288c158",
        "outputId": "cc1c0e98-6aaf-498b-b008-ef5114fac96f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ]
        }
      ],
      "source": [
        "# Actual\n",
        "print(target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "id": "6740a8b3-acf6-42b1-8dc2-02a4b3166135",
      "metadata": {
        "id": "6740a8b3-acf6-42b1-8dc2-02a4b3166135"
      },
      "outputs": [],
      "source": [
        "# Loss function MSE\n",
        "\n",
        "def MSE(actual,pred):\n",
        "    diff=actual-pred\n",
        "    return torch.sum(diff*diff)/diff.numel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "id": "9a262f2e-7a77-4176-92e7-732b4dae9625",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a262f2e-7a77-4176-92e7-732b4dae9625",
        "outputId": "693cb400-0891-4769-bc0b-84bbec5fa128"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(48355.1406, grad_fn=<DivBackward0>)\n"
          ]
        }
      ],
      "source": [
        "loss=MSE(target,preds)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "id": "5bf8b609-2f96-491e-9fb9-e95a27f23564",
      "metadata": {
        "id": "5bf8b609-2f96-491e-9fb9-e95a27f23564"
      },
      "outputs": [],
      "source": [
        "# Compute Gradients\n",
        "loss.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "id": "a9573681-1760-4281-a374-9c620bec7fb6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9573681-1760-4281-a374-9c620bec7fb6",
        "outputId": "aefda70c-77ed-4465-d508-4d626cfb8c5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.8495, -1.4858, -0.3431],\n",
            "        [-1.2954,  1.9983, -0.4817]], requires_grad=True)\n",
            "tensor([[-24552.4961, -27546.2559, -16739.0957],\n",
            "        [ -4861.7637,  -3888.9944,  -2849.0725]])\n"
          ]
        }
      ],
      "source": [
        "print(w)\n",
        "print(w.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "id": "281e4af7-b071-4bce-aa62-ac678706b5fd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "281e4af7-b071-4bce-aa62-ac678706b5fd",
        "outputId": "ba364072-af8c-44a6-b3e7-2bd44eb54037"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.2907,  1.0617], requires_grad=True)\n",
            "tensor([-294.0344,  -55.4218])\n"
          ]
        }
      ],
      "source": [
        "print(b)\n",
        "print(b.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "id": "1b9a3fe6-2cd3-456f-8598-e4f966ec08b9",
      "metadata": {
        "id": "1b9a3fe6-2cd3-456f-8598-e4f966ec08b9"
      },
      "outputs": [],
      "source": [
        "# adjust weight and reset grad\n",
        "with torch.no_grad():\n",
        "    w-=w.grad * 1e-5;\n",
        "    b-=b.grad * 1e-5;\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "id": "7904e6d4-99f1-4677-953e-53ae78c02342",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7904e6d4-99f1-4677-953e-53ae78c02342",
        "outputId": "60234022-c2a6-4818-fffd-d483006f69fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.6039, -1.2103, -0.1757],\n",
            "        [-1.2468,  2.0372, -0.4533]], requires_grad=True)\n",
            "tensor([-0.2878,  1.0623], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "print(w)\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "id": "ab329893-1447-48f4-8b18-37619e46536f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab329893-1447-48f4-8b18-37619e46536f",
        "outputId": "657e706b-84b2-40a2-9091-e5879df7824b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(32978.2695, grad_fn=<DivBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Calculate again\n",
        "preds=model(inputs)\n",
        "loss=MSE(target,preds)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "id": "e72865c4-d013-4c15-bddd-bfff9da17969",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e72865c4-d013-4c15-bddd-bfff9da17969",
        "outputId": "231528c8-9a22-4e25-a461-e560360f7601"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs(0/100) & Loss 32978.26953125\n",
            "Epochs(1/100) & Loss 22611.419921875\n",
            "Epochs(2/100) & Loss 15620.8076171875\n",
            "Epochs(3/100) & Loss 10905.447265625\n",
            "Epochs(4/100) & Loss 7723.4052734375\n",
            "Epochs(5/100) & Loss 5574.6982421875\n",
            "Epochs(6/100) & Loss 4122.39599609375\n",
            "Epochs(7/100) & Loss 3139.4453125\n",
            "Epochs(8/100) & Loss 2472.836669921875\n",
            "Epochs(9/100) & Loss 2019.458740234375\n",
            "Epochs(10/100) & Loss 1709.8267822265625\n",
            "Epochs(11/100) & Loss 1497.113037109375\n",
            "Epochs(12/100) & Loss 1349.7623291015625\n",
            "Epochs(13/100) & Loss 1246.509033203125\n",
            "Epochs(14/100) & Loss 1173.0211181640625\n",
            "Epochs(15/100) & Loss 1119.640380859375\n",
            "Epochs(16/100) & Loss 1079.8580322265625\n",
            "Epochs(17/100) & Loss 1049.28662109375\n",
            "Epochs(18/100) & Loss 1024.9697265625\n",
            "Epochs(19/100) & Loss 1004.9130859375\n",
            "Epochs(20/100) & Loss 987.7740478515625\n",
            "Epochs(21/100) & Loss 972.6451416015625\n",
            "Epochs(22/100) & Loss 958.916015625\n",
            "Epochs(23/100) & Loss 946.17431640625\n",
            "Epochs(24/100) & Loss 934.14111328125\n",
            "Epochs(25/100) & Loss 922.6286010742188\n",
            "Epochs(26/100) & Loss 911.5090942382812\n",
            "Epochs(27/100) & Loss 900.6964111328125\n",
            "Epochs(28/100) & Loss 890.13134765625\n",
            "Epochs(29/100) & Loss 879.7744140625\n",
            "Epochs(30/100) & Loss 869.5977783203125\n",
            "Epochs(31/100) & Loss 859.5823974609375\n",
            "Epochs(32/100) & Loss 849.7149658203125\n",
            "Epochs(33/100) & Loss 839.9861450195312\n",
            "Epochs(34/100) & Loss 830.3884887695312\n",
            "Epochs(35/100) & Loss 820.91748046875\n",
            "Epochs(36/100) & Loss 811.5689697265625\n",
            "Epochs(37/100) & Loss 802.33984375\n",
            "Epochs(38/100) & Loss 793.2277221679688\n",
            "Epochs(39/100) & Loss 784.22998046875\n",
            "Epochs(40/100) & Loss 775.34521484375\n",
            "Epochs(41/100) & Loss 766.5709838867188\n",
            "Epochs(42/100) & Loss 757.9063110351562\n",
            "Epochs(43/100) & Loss 749.3497314453125\n",
            "Epochs(44/100) & Loss 740.8995361328125\n",
            "Epochs(45/100) & Loss 732.5537719726562\n",
            "Epochs(46/100) & Loss 724.3121337890625\n",
            "Epochs(47/100) & Loss 716.1724853515625\n",
            "Epochs(48/100) & Loss 708.1337890625\n",
            "Epochs(49/100) & Loss 700.1948852539062\n",
            "Epochs(50/100) & Loss 692.3544921875\n",
            "Epochs(51/100) & Loss 684.611328125\n",
            "Epochs(52/100) & Loss 676.9636840820312\n",
            "Epochs(53/100) & Loss 669.4109497070312\n",
            "Epochs(54/100) & Loss 661.9519653320312\n",
            "Epochs(55/100) & Loss 654.5848388671875\n",
            "Epochs(56/100) & Loss 647.3094482421875\n",
            "Epochs(57/100) & Loss 640.123779296875\n",
            "Epochs(58/100) & Loss 633.0275268554688\n",
            "Epochs(59/100) & Loss 626.0184936523438\n",
            "Epochs(60/100) & Loss 619.0963134765625\n",
            "Epochs(61/100) & Loss 612.2595825195312\n",
            "Epochs(62/100) & Loss 605.5074462890625\n",
            "Epochs(63/100) & Loss 598.8389892578125\n",
            "Epochs(64/100) & Loss 592.2527465820312\n",
            "Epochs(65/100) & Loss 585.7476806640625\n",
            "Epochs(66/100) & Loss 579.3232421875\n",
            "Epochs(67/100) & Loss 572.9779052734375\n",
            "Epochs(68/100) & Loss 566.7110595703125\n",
            "Epochs(69/100) & Loss 560.5215454101562\n",
            "Epochs(70/100) & Loss 554.4083251953125\n",
            "Epochs(71/100) & Loss 548.37060546875\n",
            "Epochs(72/100) & Loss 542.4071044921875\n",
            "Epochs(73/100) & Loss 536.5173950195312\n",
            "Epochs(74/100) & Loss 530.7002563476562\n",
            "Epochs(75/100) & Loss 524.9544677734375\n",
            "Epochs(76/100) & Loss 519.2799682617188\n",
            "Epochs(77/100) & Loss 513.675048828125\n",
            "Epochs(78/100) & Loss 508.13916015625\n",
            "Epochs(79/100) & Loss 502.6714782714844\n",
            "Epochs(80/100) & Loss 497.27099609375\n",
            "Epochs(81/100) & Loss 491.9369201660156\n",
            "Epochs(82/100) & Loss 486.6685485839844\n",
            "Epochs(83/100) & Loss 481.4649353027344\n",
            "Epochs(84/100) & Loss 476.325439453125\n",
            "Epochs(85/100) & Loss 471.24884033203125\n",
            "Epochs(86/100) & Loss 466.2347717285156\n",
            "Epochs(87/100) & Loss 461.28228759765625\n",
            "Epochs(88/100) & Loss 456.39044189453125\n",
            "Epochs(89/100) & Loss 451.55877685546875\n",
            "Epochs(90/100) & Loss 446.78643798828125\n",
            "Epochs(91/100) & Loss 442.072509765625\n",
            "Epochs(92/100) & Loss 437.4165954589844\n",
            "Epochs(93/100) & Loss 432.8175354003906\n",
            "Epochs(94/100) & Loss 428.27490234375\n",
            "Epochs(95/100) & Loss 423.7879333496094\n",
            "Epochs(96/100) & Loss 419.3558654785156\n",
            "Epochs(97/100) & Loss 414.97808837890625\n",
            "Epochs(98/100) & Loss 410.6539611816406\n",
            "Epochs(99/100) & Loss 406.38287353515625\n",
            "Epochs(100/100) & Loss 402.163818359375\n",
            "Epochs(101/100) & Loss 397.996337890625\n",
            "Epochs(102/100) & Loss 393.8797912597656\n",
            "Epochs(103/100) & Loss 389.81365966796875\n",
            "Epochs(104/100) & Loss 385.79705810546875\n",
            "Epochs(105/100) & Loss 381.82965087890625\n",
            "Epochs(106/100) & Loss 377.91046142578125\n",
            "Epochs(107/100) & Loss 374.03900146484375\n",
            "Epochs(108/100) & Loss 370.2151184082031\n",
            "Epochs(109/100) & Loss 366.43768310546875\n",
            "Epochs(110/100) & Loss 362.70635986328125\n",
            "Epochs(111/100) & Loss 359.02044677734375\n",
            "Epochs(112/100) & Loss 355.3794860839844\n",
            "Epochs(113/100) & Loss 351.7828369140625\n",
            "Epochs(114/100) & Loss 348.22991943359375\n",
            "Epochs(115/100) & Loss 344.72021484375\n",
            "Epochs(116/100) & Loss 341.25311279296875\n",
            "Epochs(117/100) & Loss 337.828125\n",
            "Epochs(118/100) & Loss 334.44488525390625\n",
            "Epochs(119/100) & Loss 331.10272216796875\n",
            "Epochs(120/100) & Loss 327.80096435546875\n",
            "Epochs(121/100) & Loss 324.5395202636719\n",
            "Epochs(122/100) & Loss 321.31732177734375\n",
            "Epochs(123/100) & Loss 318.13433837890625\n",
            "Epochs(124/100) & Loss 314.9901123046875\n",
            "Epochs(125/100) & Loss 311.8839111328125\n",
            "Epochs(126/100) & Loss 308.8153076171875\n",
            "Epochs(127/100) & Loss 305.78363037109375\n",
            "Epochs(128/100) & Loss 302.78875732421875\n",
            "Epochs(129/100) & Loss 299.8302307128906\n",
            "Epochs(130/100) & Loss 296.90740966796875\n",
            "Epochs(131/100) & Loss 294.01971435546875\n",
            "Epochs(132/100) & Loss 291.1670837402344\n",
            "Epochs(133/100) & Loss 288.34881591796875\n",
            "Epochs(134/100) & Loss 285.56439208984375\n",
            "Epochs(135/100) & Loss 282.813720703125\n",
            "Epochs(136/100) & Loss 280.09637451171875\n",
            "Epochs(137/100) & Loss 277.41131591796875\n",
            "Epochs(138/100) & Loss 274.75885009765625\n",
            "Epochs(139/100) & Loss 272.13836669921875\n",
            "Epochs(140/100) & Loss 269.54925537109375\n",
            "Epochs(141/100) & Loss 266.99139404296875\n",
            "Epochs(142/100) & Loss 264.4642028808594\n",
            "Epochs(143/100) & Loss 261.96746826171875\n",
            "Epochs(144/100) & Loss 259.50042724609375\n",
            "Epochs(145/100) & Loss 257.0630798339844\n",
            "Epochs(146/100) & Loss 254.6551055908203\n",
            "Epochs(147/100) & Loss 252.2760009765625\n",
            "Epochs(148/100) & Loss 249.92529296875\n",
            "Epochs(149/100) & Loss 247.60275268554688\n",
            "Epochs(150/100) & Loss 245.3078155517578\n",
            "Epochs(151/100) & Loss 243.04052734375\n",
            "Epochs(152/100) & Loss 240.80020141601562\n",
            "Epochs(153/100) & Loss 238.58676147460938\n",
            "Epochs(154/100) & Loss 236.39968872070312\n",
            "Epochs(155/100) & Loss 234.2386932373047\n",
            "Epochs(156/100) & Loss 232.1033935546875\n",
            "Epochs(157/100) & Loss 229.99374389648438\n",
            "Epochs(158/100) & Loss 227.9089813232422\n",
            "Epochs(159/100) & Loss 225.8491668701172\n",
            "Epochs(160/100) & Loss 223.8138427734375\n",
            "Epochs(161/100) & Loss 221.80270385742188\n",
            "Epochs(162/100) & Loss 219.8154296875\n",
            "Epochs(163/100) & Loss 217.85165405273438\n",
            "Epochs(164/100) & Loss 215.91122436523438\n",
            "Epochs(165/100) & Loss 213.99404907226562\n",
            "Epochs(166/100) & Loss 212.0993194580078\n",
            "Epochs(167/100) & Loss 210.2268524169922\n",
            "Epochs(168/100) & Loss 208.3769989013672\n",
            "Epochs(169/100) & Loss 206.5486602783203\n",
            "Epochs(170/100) & Loss 204.7421112060547\n",
            "Epochs(171/100) & Loss 202.956787109375\n",
            "Epochs(172/100) & Loss 201.1925506591797\n",
            "Epochs(173/100) & Loss 199.4490966796875\n",
            "Epochs(174/100) & Loss 197.72621154785156\n",
            "Epochs(175/100) & Loss 196.02369689941406\n",
            "Epochs(176/100) & Loss 194.34107971191406\n",
            "Epochs(177/100) & Loss 192.67813110351562\n",
            "Epochs(178/100) & Loss 191.03504943847656\n",
            "Epochs(179/100) & Loss 189.41098022460938\n",
            "Epochs(180/100) & Loss 187.8060302734375\n",
            "Epochs(181/100) & Loss 186.22000122070312\n",
            "Epochs(182/100) & Loss 184.65237426757812\n",
            "Epochs(183/100) & Loss 183.10324096679688\n",
            "Epochs(184/100) & Loss 181.57223510742188\n",
            "Epochs(185/100) & Loss 180.0590362548828\n",
            "Epochs(186/100) & Loss 178.5635223388672\n",
            "Epochs(187/100) & Loss 177.08541870117188\n",
            "Epochs(188/100) & Loss 175.6246337890625\n",
            "Epochs(189/100) & Loss 174.18069458007812\n",
            "Epochs(190/100) & Loss 172.753662109375\n",
            "Epochs(191/100) & Loss 171.3431396484375\n",
            "Epochs(192/100) & Loss 169.9491424560547\n",
            "Epochs(193/100) & Loss 168.5712432861328\n",
            "Epochs(194/100) & Loss 167.20945739746094\n",
            "Epochs(195/100) & Loss 165.8631591796875\n",
            "Epochs(196/100) & Loss 164.53269958496094\n",
            "Epochs(197/100) & Loss 163.2175750732422\n",
            "Epochs(198/100) & Loss 161.91757202148438\n",
            "Epochs(199/100) & Loss 160.6326904296875\n",
            "Epochs(200/100) & Loss 159.36245727539062\n",
            "Epochs(201/100) & Loss 158.1071319580078\n",
            "Epochs(202/100) & Loss 156.86598205566406\n",
            "Epochs(203/100) & Loss 155.63919067382812\n",
            "Epochs(204/100) & Loss 154.42660522460938\n",
            "Epochs(205/100) & Loss 153.22784423828125\n",
            "Epochs(206/100) & Loss 152.0428466796875\n",
            "Epochs(207/100) & Loss 150.8713836669922\n",
            "Epochs(208/100) & Loss 149.71334838867188\n",
            "Epochs(209/100) & Loss 148.56866455078125\n",
            "Epochs(210/100) & Loss 147.43692016601562\n",
            "Epochs(211/100) & Loss 146.31808471679688\n",
            "Epochs(212/100) & Loss 145.21217346191406\n",
            "Epochs(213/100) & Loss 144.1187744140625\n",
            "Epochs(214/100) & Loss 143.03778076171875\n",
            "Epochs(215/100) & Loss 141.9689483642578\n",
            "Epochs(216/100) & Loss 140.91236877441406\n",
            "Epochs(217/100) & Loss 139.86776733398438\n",
            "Epochs(218/100) & Loss 138.83506774902344\n",
            "Epochs(219/100) & Loss 137.81393432617188\n",
            "Epochs(220/100) & Loss 136.80441284179688\n",
            "Epochs(221/100) & Loss 135.80618286132812\n",
            "Epochs(222/100) & Loss 134.81936645507812\n",
            "Epochs(223/100) & Loss 133.8436279296875\n",
            "Epochs(224/100) & Loss 132.87884521484375\n",
            "Epochs(225/100) & Loss 131.9249267578125\n",
            "Epochs(226/100) & Loss 130.98165893554688\n",
            "Epochs(227/100) & Loss 130.04891967773438\n",
            "Epochs(228/100) & Loss 129.1267547607422\n",
            "Epochs(229/100) & Loss 128.21481323242188\n",
            "Epochs(230/100) & Loss 127.31315612792969\n",
            "Epochs(231/100) & Loss 126.42146301269531\n",
            "Epochs(232/100) & Loss 125.5396728515625\n",
            "Epochs(233/100) & Loss 124.66788482666016\n",
            "Epochs(234/100) & Loss 123.80558013916016\n",
            "Epochs(235/100) & Loss 122.95295715332031\n",
            "Epochs(236/100) & Loss 122.10970306396484\n",
            "Epochs(237/100) & Loss 121.27583312988281\n",
            "Epochs(238/100) & Loss 120.4511947631836\n",
            "Epochs(239/100) & Loss 119.63566589355469\n",
            "Epochs(240/100) & Loss 118.82914733886719\n",
            "Epochs(241/100) & Loss 118.03153991699219\n",
            "Epochs(242/100) & Loss 117.24263000488281\n",
            "Epochs(243/100) & Loss 116.46244049072266\n",
            "Epochs(244/100) & Loss 115.69071197509766\n",
            "Epochs(245/100) & Loss 114.92759704589844\n",
            "Epochs(246/100) & Loss 114.17268371582031\n",
            "Epochs(247/100) & Loss 113.42610931396484\n",
            "Epochs(248/100) & Loss 112.6877212524414\n",
            "Epochs(249/100) & Loss 111.95732116699219\n",
            "Epochs(250/100) & Loss 111.23477935791016\n",
            "Epochs(251/100) & Loss 110.52010345458984\n",
            "Epochs(252/100) & Loss 109.81317138671875\n",
            "Epochs(253/100) & Loss 109.11387634277344\n",
            "Epochs(254/100) & Loss 108.42220306396484\n",
            "Epochs(255/100) & Loss 107.73812103271484\n",
            "Epochs(256/100) & Loss 107.06126403808594\n",
            "Epochs(257/100) & Loss 106.3916244506836\n",
            "Epochs(258/100) & Loss 105.7293930053711\n",
            "Epochs(259/100) & Loss 105.07401275634766\n",
            "Epochs(260/100) & Loss 104.42581939697266\n",
            "Epochs(261/100) & Loss 103.78459167480469\n",
            "Epochs(262/100) & Loss 103.1501235961914\n",
            "Epochs(263/100) & Loss 102.52235412597656\n",
            "Epochs(264/100) & Loss 101.90129089355469\n",
            "Epochs(265/100) & Loss 101.28697967529297\n",
            "Epochs(266/100) & Loss 100.67909240722656\n",
            "Epochs(267/100) & Loss 100.07758331298828\n",
            "Epochs(268/100) & Loss 99.48255920410156\n",
            "Epochs(269/100) & Loss 98.89366149902344\n",
            "Epochs(270/100) & Loss 98.31108093261719\n",
            "Epochs(271/100) & Loss 97.7344970703125\n",
            "Epochs(272/100) & Loss 97.16404724121094\n",
            "Epochs(273/100) & Loss 96.59966278076172\n",
            "Epochs(274/100) & Loss 96.04112243652344\n",
            "Epochs(275/100) & Loss 95.48839569091797\n",
            "Epochs(276/100) & Loss 94.94143676757812\n",
            "Epochs(277/100) & Loss 94.40010070800781\n",
            "Epochs(278/100) & Loss 93.8643798828125\n",
            "Epochs(279/100) & Loss 93.33425903320312\n",
            "Epochs(280/100) & Loss 92.80970001220703\n",
            "Epochs(281/100) & Loss 92.2905502319336\n",
            "Epochs(282/100) & Loss 91.77659606933594\n",
            "Epochs(283/100) & Loss 91.26807403564453\n",
            "Epochs(284/100) & Loss 90.76469421386719\n",
            "Epochs(285/100) & Loss 90.2665786743164\n",
            "Epochs(286/100) & Loss 89.77348327636719\n",
            "Epochs(287/100) & Loss 89.28546142578125\n",
            "Epochs(288/100) & Loss 88.80224609375\n",
            "Epochs(289/100) & Loss 88.32403564453125\n",
            "Epochs(290/100) & Loss 87.85074615478516\n",
            "Epochs(291/100) & Loss 87.38221740722656\n",
            "Epochs(292/100) & Loss 86.9184341430664\n",
            "Epochs(293/100) & Loss 86.4592056274414\n",
            "Epochs(294/100) & Loss 86.00483703613281\n",
            "Epochs(295/100) & Loss 85.55482482910156\n",
            "Epochs(296/100) & Loss 85.10944366455078\n",
            "Epochs(297/100) & Loss 84.66838836669922\n",
            "Epochs(298/100) & Loss 84.23180389404297\n",
            "Epochs(299/100) & Loss 83.79957580566406\n",
            "Epochs(300/100) & Loss 83.37158966064453\n",
            "Epochs(301/100) & Loss 82.94792175292969\n",
            "Epochs(302/100) & Loss 82.52845001220703\n",
            "Epochs(303/100) & Loss 82.11302947998047\n",
            "Epochs(304/100) & Loss 81.70178985595703\n",
            "Epochs(305/100) & Loss 81.29443359375\n",
            "Epochs(306/100) & Loss 80.89115905761719\n",
            "Epochs(307/100) & Loss 80.49191284179688\n",
            "Epochs(308/100) & Loss 80.09648895263672\n",
            "Epochs(309/100) & Loss 79.70487976074219\n",
            "Epochs(310/100) & Loss 79.31706237792969\n",
            "Epochs(311/100) & Loss 78.93302154541016\n",
            "Epochs(312/100) & Loss 78.55270385742188\n",
            "Epochs(313/100) & Loss 78.17608642578125\n",
            "Epochs(314/100) & Loss 77.80305480957031\n",
            "Epochs(315/100) & Loss 77.43354797363281\n",
            "Epochs(316/100) & Loss 77.06768035888672\n",
            "Epochs(317/100) & Loss 76.70521545410156\n",
            "Epochs(318/100) & Loss 76.34623718261719\n",
            "Epochs(319/100) & Loss 75.99064636230469\n",
            "Epochs(320/100) & Loss 75.638427734375\n",
            "Epochs(321/100) & Loss 75.28965759277344\n",
            "Epochs(322/100) & Loss 74.94390869140625\n",
            "Epochs(323/100) & Loss 74.6016616821289\n",
            "Epochs(324/100) & Loss 74.26252746582031\n",
            "Epochs(325/100) & Loss 73.92643737792969\n",
            "Epochs(326/100) & Loss 73.59371948242188\n",
            "Epochs(327/100) & Loss 73.26400756835938\n",
            "Epochs(328/100) & Loss 72.93724060058594\n",
            "Epochs(329/100) & Loss 72.61355590820312\n",
            "Epochs(330/100) & Loss 72.29293823242188\n",
            "Epochs(331/100) & Loss 71.97520446777344\n",
            "Epochs(332/100) & Loss 71.66041564941406\n",
            "Epochs(333/100) & Loss 71.34851837158203\n",
            "Epochs(334/100) & Loss 71.03936004638672\n",
            "Epochs(335/100) & Loss 70.73307037353516\n",
            "Epochs(336/100) & Loss 70.42965698242188\n",
            "Epochs(337/100) & Loss 70.1288070678711\n",
            "Epochs(338/100) & Loss 69.83082580566406\n",
            "Epochs(339/100) & Loss 69.53546905517578\n",
            "Epochs(340/100) & Loss 69.24275207519531\n",
            "Epochs(341/100) & Loss 68.9526138305664\n",
            "Epochs(342/100) & Loss 68.66511535644531\n",
            "Epochs(343/100) & Loss 68.38011169433594\n",
            "Epochs(344/100) & Loss 68.09770965576172\n",
            "Epochs(345/100) & Loss 67.8177719116211\n",
            "Epochs(346/100) & Loss 67.54031372070312\n",
            "Epochs(347/100) & Loss 67.26530456542969\n",
            "Epochs(348/100) & Loss 66.99262237548828\n",
            "Epochs(349/100) & Loss 66.72248840332031\n",
            "Epochs(350/100) & Loss 66.45446014404297\n",
            "Epochs(351/100) & Loss 66.18887329101562\n",
            "Epochs(352/100) & Loss 65.9256591796875\n",
            "Epochs(353/100) & Loss 65.66461944580078\n",
            "Epochs(354/100) & Loss 65.4058609008789\n",
            "Epochs(355/100) & Loss 65.14920043945312\n",
            "Epochs(356/100) & Loss 64.89493560791016\n",
            "Epochs(357/100) & Loss 64.64276123046875\n",
            "Epochs(358/100) & Loss 64.39266204833984\n",
            "Epochs(359/100) & Loss 64.14469909667969\n",
            "Epochs(360/100) & Loss 63.8988151550293\n",
            "Epochs(361/100) & Loss 63.65502166748047\n",
            "Epochs(362/100) & Loss 63.41322708129883\n",
            "Epochs(363/100) & Loss 63.1735954284668\n",
            "Epochs(364/100) & Loss 62.935791015625\n",
            "Epochs(365/100) & Loss 62.70008087158203\n",
            "Epochs(366/100) & Loss 62.4661865234375\n",
            "Epochs(367/100) & Loss 62.23429489135742\n",
            "Epochs(368/100) & Loss 62.00431442260742\n",
            "Epochs(369/100) & Loss 61.77619171142578\n",
            "Epochs(370/100) & Loss 61.549949645996094\n",
            "Epochs(371/100) & Loss 61.32550048828125\n",
            "Epochs(372/100) & Loss 61.10285568237305\n",
            "Epochs(373/100) & Loss 60.88207244873047\n",
            "Epochs(374/100) & Loss 60.66301727294922\n",
            "Epochs(375/100) & Loss 60.445716857910156\n",
            "Epochs(376/100) & Loss 60.2302131652832\n",
            "Epochs(377/100) & Loss 60.0163688659668\n",
            "Epochs(378/100) & Loss 59.80409622192383\n",
            "Epochs(379/100) & Loss 59.59367752075195\n",
            "Epochs(380/100) & Loss 59.384849548339844\n",
            "Epochs(381/100) & Loss 59.17766189575195\n",
            "Epochs(382/100) & Loss 58.972068786621094\n",
            "Epochs(383/100) & Loss 58.76812744140625\n",
            "Epochs(384/100) & Loss 58.56578826904297\n",
            "Epochs(385/100) & Loss 58.364845275878906\n",
            "Epochs(386/100) & Loss 58.165557861328125\n",
            "Epochs(387/100) & Loss 57.9677619934082\n",
            "Epochs(388/100) & Loss 57.771522521972656\n",
            "Epochs(389/100) & Loss 57.57676315307617\n",
            "Epochs(390/100) & Loss 57.38347244262695\n",
            "Epochs(391/100) & Loss 57.19158172607422\n",
            "Epochs(392/100) & Loss 57.00123977661133\n",
            "Epochs(393/100) & Loss 56.812278747558594\n",
            "Epochs(394/100) & Loss 56.62468719482422\n",
            "Epochs(395/100) & Loss 56.438499450683594\n",
            "Epochs(396/100) & Loss 56.25371551513672\n",
            "Epochs(397/100) & Loss 56.07024383544922\n",
            "Epochs(398/100) & Loss 55.888206481933594\n",
            "Epochs(399/100) & Loss 55.70744705200195\n"
          ]
        }
      ],
      "source": [
        "# Training for multiple epochs\n",
        "for i in range(400):\n",
        "    preds=model(inputs)\n",
        "    loss=MSE(target,preds)\n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "        w-=w.grad * 1e-5; # Learning rate\n",
        "        b-=b.grad * 1e-5;\n",
        "        w.grad.zero_()\n",
        "        b.grad.zero_()\n",
        "    print(f\"Epochs({i}/{100}) & Loss {loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "id": "c92aab22-20d1-4de7-8eec-bce4d9f1776d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c92aab22-20d1-4de7-8eec-bce4d9f1776d",
        "outputId": "e8916b51-d845-44e0-e88c-07ba6dd2ac74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(55.5280, grad_fn=<DivBackward0>)\n"
          ]
        }
      ],
      "source": [
        "preds=model(inputs)\n",
        "loss=MSE(target,preds)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "id": "ea9c4514-0a78-4b21-8c71-35ccffcf7a4a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea9c4514-0a78-4b21-8c71-35ccffcf7a4a",
        "outputId": "695286c1-a30e-4602-912a-46307619fded"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.4517117166007045"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ],
      "source": [
        "from math import sqrt\n",
        "sqrt(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "id": "cb34b1ff-1c11-4609-81ad-a36958650c1d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb34b1ff-1c11-4609-81ad-a36958650c1d",
        "outputId": "9cc60a0c-d939-4b8d-945e-e57c1b5f9676"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 57.8998,  70.4368],\n",
              "        [ 82.8202,  92.9607],\n",
              "        [116.1162, 150.2901],\n",
              "        [ 25.6364,  35.9291],\n",
              "        [100.2740, 106.5714]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ],
      "source": [
        "preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "id": "8b65fefa-9a5f-4d05-8c1f-aca2064d7946",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b65fefa-9a5f-4d05-8c1f-aca2064d7946",
        "outputId": "92536058-d557-44ce-956f-11d267291753"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.]])"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ],
      "source": [
        "target"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3589cf79-8577-4b7f-8948-112cb2af410a",
      "metadata": {
        "id": "3589cf79-8577-4b7f-8948-112cb2af410a"
      },
      "source": [
        "- Therfore we can see that they are almost close each other"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4879a9ec-e8b8-40e1-9e54-b65c11aab1c7",
      "metadata": {
        "id": "4879a9ec-e8b8-40e1-9e54-b65c11aab1c7"
      },
      "source": [
        "### Neural Network using PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "id": "961c6c38-54d9-48dc-ba6a-711714f435a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "961c6c38-54d9-48dc-ba6a-711714f435a0",
        "outputId": "5e59c2c3-079d-411f-a50d-2e25e9a3cb45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "# To check GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Mx6chszEdwtL"
      },
      "id": "Mx6chszEdwtL",
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Training data from open datasets\n",
        "training_data=datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "DgrTfbW6iHtP"
      },
      "id": "DgrTfbW6iHtP",
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data=datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "enNdVARDidin"
      },
      "id": "enNdVARDidin",
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(training_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "pYOzQCCFirbW",
        "outputId": "2f5bf2d1-ab0f-4a77-a2a0-f848836e33aa"
      },
      "id": "pYOzQCCFirbW",
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torchvision.datasets.mnist.FashionMNIST"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>torchvision.datasets.mnist.FashionMNIST</b><br/>def __init__(root: Union[str, Path], train: bool=True, transform: Optional[Callable]=None, target_transform: Optional[Callable]=None, download: bool=False) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py</a>`Fashion-MNIST &lt;https://github.com/zalandoresearch/fashion-mnist&gt;`_ Dataset.\n",
              "\n",
              "Args:\n",
              "    root (str or ``pathlib.Path``): Root directory of dataset where ``FashionMNIST/raw/train-images-idx3-ubyte``\n",
              "        and  ``FashionMNIST/raw/t10k-images-idx3-ubyte`` exist.\n",
              "    train (bool, optional): If True, creates dataset from ``train-images-idx3-ubyte``,\n",
              "        otherwise from ``t10k-images-idx3-ubyte``.\n",
              "    download (bool, optional): If True, downloads the dataset from the internet and\n",
              "        puts it in root directory. If dataset is already downloaded, it is not\n",
              "        downloaded again.\n",
              "    transform (callable, optional): A function/transform that  takes in a PIL image\n",
              "        and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
              "    target_transform (callable, optional): A function/transform that takes in the\n",
              "        target and transforms it.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 203);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=64"
      ],
      "metadata": {
        "id": "3EgKvsYMiwqj"
      },
      "id": "3EgKvsYMiwqj",
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Data Loaders\n",
        "train_dataloader=DataLoader(training_data,batch_size=batch_size)\n",
        "test_dataloader=DataLoader(test_data,batch_size=batch_size)"
      ],
      "metadata": {
        "id": "JEV9wO5gi4hs"
      },
      "id": "JEV9wO5gi4hs",
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for X,y in test_dataloader:\n",
        "    print(\"Shape of X [N,C,H,W]: \",X.shape)\n",
        "    print(\"Shape of y: \",y.shape,y.dtype)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvPazp8fi__j",
        "outputId": "121307f3-68fd-40c4-c7b5-0a38dc4e2c7c"
      },
      "id": "DvPazp8fi__j",
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N,C,H,W]:  torch.Size([64, 1, 28, 28])\n",
            "Shape of y:  torch.Size([64]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2BJ25vMjFzV",
        "outputId": "f8adf90a-8cfc-4213-dfc9-5aef45f08dd2"
      },
      "id": "W2BJ25vMjFzV",
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([9, 2, 1, 1, 6, 1, 4, 6, 5, 7, 4, 5, 7, 3, 4, 1, 2, 4, 8, 0, 2, 5, 7, 9,\n",
            "        1, 4, 6, 0, 9, 3, 8, 8, 3, 3, 8, 0, 7, 5, 7, 9, 6, 1, 3, 7, 6, 7, 2, 1,\n",
            "        2, 2, 4, 4, 5, 8, 2, 2, 8, 4, 8, 0, 7, 7, 8, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get CPU or GPU device for Training\n",
        "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} device\".format(device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3961rD9klTU_",
        "outputId": "c04487fe-8858-43dd-b692-7ec37fcce4d4"
      },
      "id": "3961rD9klTU_",
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Model\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork,self).__init__()\n",
        "    self.flatten=nn.Flatten()\n",
        "    self.linear_relu_stack=nn.Sequential(\n",
        "        nn.Linear(28*28,512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512,512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512,10),\n",
        "        nn.Softmax()\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    x=self.flatten(x)\n",
        "    logits=self.linear_relu_stack(x)\n",
        "    return logits\n",
        "\n",
        "model=NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOIlsCN3lgg3",
        "outputId": "f251fa58-c86c-43d7-aae8-8ddf77ff775e"
      },
      "id": "fOIlsCN3lgg3",
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (5): Softmax(dim=None)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=1e-3)"
      ],
      "metadata": {
        "id": "ducVaHEan7pL"
      },
      "id": "ducVaHEan7pL",
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader,model,loss_fn,optimizer):\n",
        "  size=len(dataloader.dataset)\n",
        "  for batch,(X,y) in enumerate(dataloader):\n",
        "    X,y=X.to(device),y.to(device)\n",
        "    # Compute prediction error\n",
        "    pred=model(X)\n",
        "    loss=loss_fn(pred,y)\n",
        "    # Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if batch % 100 == 0:\n",
        "      loss,current=loss.item(),batch*len(X)\n",
        "      print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n"
      ],
      "metadata": {
        "id": "kbD6_wmiojw8"
      },
      "id": "kbD6_wmiojw8",
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader,model,loss_fn):\n",
        "  size=len(dataloader.dataset)\n",
        "  num_batches=len(dataloader)\n",
        "  model.eval()\n",
        "  test_loss,correct=0,0\n",
        "  with torch.no_grad():\n",
        "    for X,y in dataloader:\n",
        "      X,y=X.to(device),y.to(device)\n",
        "      pred=model(X)\n",
        "      test_loss+=loss_fn(pred,y).item()\n",
        "      correct+=(pred.argmax(1)==y).type(torch.float).sum().item()\n",
        "  test_loss/=num_batches\n",
        "  print(f\"Test Error: \\n Accuracy: {(100*correct/size):>0.1f}%, Avg loss: {test_loss:>8f}\")"
      ],
      "metadata": {
        "id": "RkqRq9n9tybE"
      },
      "id": "RkqRq9n9tybE",
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=5\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "  train(train_dataloader,model,loss_fn,optimizer)\n",
        "  test(test_dataloader,model,loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOb83aSsuNH8",
        "outputId": "92274d62-8cc8-4ebb-d9e1-9e8b32016ce3"
      },
      "id": "SOb83aSsuNH8",
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.295351 [    0/60000]\n",
            "loss: 2.295227 [ 6400/60000]\n",
            "loss: 2.295760 [12800/60000]\n",
            "loss: 2.297221 [19200/60000]\n",
            "loss: 2.293325 [25600/60000]\n",
            "loss: 2.294288 [32000/60000]\n",
            "loss: 2.294695 [38400/60000]\n",
            "loss: 2.294099 [44800/60000]\n",
            "loss: 2.293982 [51200/60000]\n",
            "loss: 2.293476 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 29.0%, Avg loss: 2.293744\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.293662 [    0/60000]\n",
            "loss: 2.293514 [ 6400/60000]\n",
            "loss: 2.293855 [12800/60000]\n",
            "loss: 2.295739 [19200/60000]\n",
            "loss: 2.291290 [25600/60000]\n",
            "loss: 2.292038 [32000/60000]\n",
            "loss: 2.293017 [38400/60000]\n",
            "loss: 2.291974 [44800/60000]\n",
            "loss: 2.292151 [51200/60000]\n",
            "loss: 2.291474 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 31.6%, Avg loss: 2.291699\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 2.291777 [    0/60000]\n",
            "loss: 2.291592 [ 6400/60000]\n",
            "loss: 2.291725 [12800/60000]\n",
            "loss: 2.294096 [19200/60000]\n",
            "loss: 2.288957 [25600/60000]\n",
            "loss: 2.289477 [32000/60000]\n",
            "loss: 2.291099 [38400/60000]\n",
            "loss: 2.289533 [44800/60000]\n",
            "loss: 2.290076 [51200/60000]\n",
            "loss: 2.289201 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 33.8%, Avg loss: 2.289374\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 2.289646 [    0/60000]\n",
            "loss: 2.289389 [ 6400/60000]\n",
            "loss: 2.289307 [12800/60000]\n",
            "loss: 2.292223 [19200/60000]\n",
            "loss: 2.286231 [25600/60000]\n",
            "loss: 2.286529 [32000/60000]\n",
            "loss: 2.288877 [38400/60000]\n",
            "loss: 2.286692 [44800/60000]\n",
            "loss: 2.287702 [51200/60000]\n",
            "loss: 2.286557 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 35.7%, Avg loss: 2.286691\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 2.287203 [    0/60000]\n",
            "loss: 2.286826 [ 6400/60000]\n",
            "loss: 2.286527 [12800/60000]\n",
            "loss: 2.290058 [19200/60000]\n",
            "loss: 2.282996 [25600/60000]\n",
            "loss: 2.283079 [32000/60000]\n",
            "loss: 2.286282 [38400/60000]\n",
            "loss: 2.283353 [44800/60000]\n",
            "loss: 2.284941 [51200/60000]\n",
            "loss: 2.283442 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 37.2%, Avg loss: 2.283552\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save model\n",
        "torch.save(model.state_dict(),\"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nK8gEwGWuX1S",
        "outputId": "53134a00-acde-48b5-8ab4-7e8901c8bc4c"
      },
      "id": "nK8gEwGWuX1S",
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load model\n",
        "model.load_state_dict(torch.load(\"model.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkfRAhT9wkb6",
        "outputId": "afe69c0f-1b5e-4a4c-dd68-7bdf9a0813bc"
      },
      "id": "XkfRAhT9wkb6",
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Prediction\n",
        "\n",
        "classes=[\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\"\n",
        "    ]\n",
        "\n",
        "model.eval()\n",
        "x,y=test_data[0][0],test_data[0][1]\n",
        "with torch.no_grad():\n",
        "  pred=model(x)\n",
        "  predicted,actual=classes[pred[0].argmax(0)],classes[y]\n",
        "  print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiGVPfFQwpDu",
        "outputId": "f0aa4bad-dc0f-410c-b590-d7409a8ca9ea"
      },
      "id": "PiGVPfFQwpDu",
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1532: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}